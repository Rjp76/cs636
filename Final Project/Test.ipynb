{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xgboost)\n",
    "data(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Species factor to an integer class starting at 0\n",
    "# This is picky, but it's a requirement for XGBoost\n",
    "species = iris$Species\n",
    "label = as.integer(iris$Species)-1\n",
    "iris$Species = NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nrow(iris)\n",
    "train.index = sample(n,floor(0.75*n))\n",
    "train.data = as.matrix(iris[train.index,])\n",
    "train.label = label[train.index]\n",
    "test.data = as.matrix(iris[-train.index,])\n",
    "test.label = label[-train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the two data sets into xgb.Matrix\n",
    "xgb.train = xgb.DMatrix(data=train.data,label=train.label)\n",
    "xgb.test = xgb.DMatrix(data=test.data,label=test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for multinomial classification\n",
    "num_class = length(levels(species))\n",
    "params = list(\n",
    "  booster=\"gbtree\",\n",
    "  eta=0.001,\n",
    "  max_depth=5,\n",
    "  gamma=3,\n",
    "  subsample=0.75,\n",
    "  colsample_bytree=1,\n",
    "  objective=\"multi:softprob\",\n",
    "  eval_metric=\"mlogloss\",\n",
    "  num_class=num_class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(unique(species))\n",
    "length(levels(species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "##### xgb.Booster\n",
       "raw: 3.7 Mb \n",
       "call:\n",
       "  xgb.train(params = params, data = xgb.train, nrounds = 10000, \n",
       "    watchlist = list(val1 = xgb.train, val2 = xgb.test), verbose = 0, \n",
       "    early_stopping_rounds = 10, nthreads = 1)\n",
       "params (as set within xgb.train):\n",
       "  booster = \"gbtree\", eta = \"0.001\", max_depth = \"5\", gamma = \"3\", subsample = \"0.75\", colsample_bytree = \"1\", objective = \"multi:softprob\", eval_metric = \"mlogloss\", num_class = \"3\", nthreads = \"1\", silent = \"1\"\n",
       "xgb.attributes:\n",
       "  best_iteration, best_msg, best_ntreelimit, best_score, niter\n",
       "callbacks:\n",
       "  cb.evaluation.log()\n",
       "  cb.early.stop(stopping_rounds = early_stopping_rounds, maximize = maximize, \n",
       "    verbose = verbose)\n",
       "# of features: 4 \n",
       "niter: 3309\n",
       "best_iteration : 3299 \n",
       "best_ntreelimit : 3299 \n",
       "best_score : 0.159404 \n",
       "nfeatures : 4 \n",
       "evaluation_log:\n",
       "    iter val1_mlogloss val2_mlogloss\n",
       "       1      1.097433      1.097470\n",
       "       2      1.096202      1.096206\n",
       "---                                 \n",
       "    3308      0.192697      0.159404\n",
       "    3309      0.192697      0.159405"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the XGBoost classifer\n",
    "xgb.fit=xgb.train(\n",
    "  params=params,\n",
    "  data=xgb.train,\n",
    "  nrounds=10000,\n",
    "  nthreads=1,\n",
    "  early_stopping_rounds=10,\n",
    "  watchlist=list(val1=xgb.train,val2=xgb.test),\n",
    "  verbose=0\n",
    ")\n",
    "\n",
    "# Review the final model and results\n",
    "xgb.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict outcomes with the test data\n",
    "xgb.pred = predict(xgb.fit,test.data,reshape=T)\n",
    "xgb.pred = as.data.frame(xgb.pred)\n",
    "colnames(xgb.pred) = levels(species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>setosa</th><th scope=col>versicolor</th><th scope=col>virginica</th><th scope=col>prediction</th><th scope=col>label</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.8932503 </td><td>0.06230251</td><td>0.04444717</td><td>setosa    </td><td>setosa    </td></tr>\n",
       "\t<tr><td>0.8938478 </td><td>0.06167523</td><td>0.04447690</td><td>setosa    </td><td>setosa    </td></tr>\n",
       "\t<tr><td>0.8938478 </td><td>0.06167523</td><td>0.04447690</td><td>setosa    </td><td>setosa    </td></tr>\n",
       "\t<tr><td>0.8932503 </td><td>0.06230251</td><td>0.04444717</td><td>setosa    </td><td>setosa    </td></tr>\n",
       "\t<tr><td>0.8932503 </td><td>0.06230251</td><td>0.04444717</td><td>setosa    </td><td>setosa    </td></tr>\n",
       "\t<tr><td>0.8940770 </td><td>0.06143461</td><td>0.04448831</td><td>setosa    </td><td>setosa    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " setosa & versicolor & virginica & prediction & label\\\\\n",
       "\\hline\n",
       "\t 0.8932503  & 0.06230251 & 0.04444717 & setosa     & setosa    \\\\\n",
       "\t 0.8938478  & 0.06167523 & 0.04447690 & setosa     & setosa    \\\\\n",
       "\t 0.8938478  & 0.06167523 & 0.04447690 & setosa     & setosa    \\\\\n",
       "\t 0.8932503  & 0.06230251 & 0.04444717 & setosa     & setosa    \\\\\n",
       "\t 0.8932503  & 0.06230251 & 0.04444717 & setosa     & setosa    \\\\\n",
       "\t 0.8940770  & 0.06143461 & 0.04448831 & setosa     & setosa    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| setosa | versicolor | virginica | prediction | label |\n",
       "|---|---|---|---|---|\n",
       "| 0.8932503  | 0.06230251 | 0.04444717 | setosa     | setosa     |\n",
       "| 0.8938478  | 0.06167523 | 0.04447690 | setosa     | setosa     |\n",
       "| 0.8938478  | 0.06167523 | 0.04447690 | setosa     | setosa     |\n",
       "| 0.8932503  | 0.06230251 | 0.04444717 | setosa     | setosa     |\n",
       "| 0.8932503  | 0.06230251 | 0.04444717 | setosa     | setosa     |\n",
       "| 0.8940770  | 0.06143461 | 0.04448831 | setosa     | setosa     |\n",
       "\n"
      ],
      "text/plain": [
       "  setosa    versicolor virginica  prediction label \n",
       "1 0.8932503 0.06230251 0.04444717 setosa     setosa\n",
       "2 0.8938478 0.06167523 0.04447690 setosa     setosa\n",
       "3 0.8938478 0.06167523 0.04447690 setosa     setosa\n",
       "4 0.8932503 0.06230251 0.04444717 setosa     setosa\n",
       "5 0.8932503 0.06230251 0.04444717 setosa     setosa\n",
       "6 0.8940770 0.06143461 0.04448831 setosa     setosa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(xgb.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the predicted label with the highest probability\n",
    "xgb.pred$prediction = apply(xgb.pred,1,function(x) colnames(xgb.pred)[which.max(x)])\n",
    "xgb.pred$label = levels(species)[test.label+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Final Accuracy = 100.00%\"\n"
     ]
    }
   ],
   "source": [
    "# Calculate the final accuracy\n",
    "result = sum(xgb.pred$prediction==xgb.pred$label)/nrow(xgb.pred)\n",
    "print(paste(\"Final Accuracy =\",sprintf(\"%1.2f%%\", 100*result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
