{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install.packages('pROC')\n",
    "# install.packages('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(caret)\n",
    "library(pROC)\n",
    "library(plyr)\n",
    "library(boot)\n",
    "library(tidyverse)\n",
    "library(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500000\n",
    "split = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_batch_and_factor <- function(data){\n",
    "    \n",
    "    data$batch = ceiling((data$time * 10000) / batch_size) - 1\n",
    "    \n",
    "    data <- transform(\n",
    "        data,\n",
    "        time=as.numeric(time),\n",
    "        signal=as.numeric(signal),\n",
    "        open_channels=as.integer(open_channels),\n",
    "        batch=as.factor(batch)\n",
    "    )\n",
    "\n",
    "    return(data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read.csv('train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>time</dt>\n",
       "\t\t<dd>'numeric'</dd>\n",
       "\t<dt>signal</dt>\n",
       "\t\t<dd>'numeric'</dd>\n",
       "\t<dt>open_channels</dt>\n",
       "\t\t<dd>'integer'</dd>\n",
       "\t<dt>batch</dt>\n",
       "\t\t<dd>'factor'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[time] 'numeric'\n",
       "\\item[signal] 'numeric'\n",
       "\\item[open\\textbackslash{}\\_channels] 'integer'\n",
       "\\item[batch] 'factor'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "time\n",
       ":   'numeric'signal\n",
       ":   'numeric'open_channels\n",
       ":   'integer'batch\n",
       ":   'factor'\n",
       "\n"
      ],
      "text/plain": [
       "         time        signal open_channels         batch \n",
       "    \"numeric\"     \"numeric\"     \"integer\"      \"factor\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = add_batch_and_factor(train_data)\n",
    "sapply(train_data, class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>time</th><th scope=col>signal</th><th scope=col>open_channels</th><th scope=col>batch</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1251238</th><td>125.1238</td><td>-1.3132 </td><td>1       </td><td>2       </td></tr>\n",
       "\t<tr><th scope=row>1977393</th><td>197.7393</td><td>-1.4323 </td><td>1       </td><td>3       </td></tr>\n",
       "\t<tr><th scope=row>1578636</th><td>157.8636</td><td> 0.6499 </td><td>3       </td><td>3       </td></tr>\n",
       "\t<tr><th scope=row>1270814</th><td>127.0814</td><td>-1.3927 </td><td>1       </td><td>2       </td></tr>\n",
       "\t<tr><th scope=row>2236367</th><td>223.6367</td><td> 2.7507 </td><td>7       </td><td>4       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & time & signal & open\\_channels & batch\\\\\n",
       "\\hline\n",
       "\t1251238 & 125.1238 & -1.3132  & 1        & 2       \\\\\n",
       "\t1977393 & 197.7393 & -1.4323  & 1        & 3       \\\\\n",
       "\t1578636 & 157.8636 &  0.6499  & 3        & 3       \\\\\n",
       "\t1270814 & 127.0814 & -1.3927  & 1        & 2       \\\\\n",
       "\t2236367 & 223.6367 &  2.7507  & 7        & 4       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | time | signal | open_channels | batch |\n",
       "|---|---|---|---|---|\n",
       "| 1251238 | 125.1238 | -1.3132  | 1        | 2        |\n",
       "| 1977393 | 197.7393 | -1.4323  | 1        | 3        |\n",
       "| 1578636 | 157.8636 |  0.6499  | 3        | 3        |\n",
       "| 1270814 | 127.0814 | -1.3927  | 1        | 2        |\n",
       "| 2236367 | 223.6367 |  2.7507  | 7        | 4        |\n",
       "\n"
      ],
      "text/plain": [
       "        time     signal  open_channels batch\n",
       "1251238 125.1238 -1.3132 1             2    \n",
       "1977393 197.7393 -1.4323 1             3    \n",
       "1578636 157.8636  0.6499 3             3    \n",
       "1270814 127.0814 -1.3927 1             2    \n",
       "2236367 223.6367  2.7507 7             4    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data[sample(nrow(train_data), 5), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>4</li>\n",
       "\t<li>5</li>\n",
       "\t<li>6</li>\n",
       "\t<li>7</li>\n",
       "\t<li>8</li>\n",
       "\t<li>9</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'0'</li>\n",
       "\t\t<li>'1'</li>\n",
       "\t\t<li>'2'</li>\n",
       "\t\t<li>'3'</li>\n",
       "\t\t<li>'4'</li>\n",
       "\t\t<li>'5'</li>\n",
       "\t\t<li>'6'</li>\n",
       "\t\t<li>'7'</li>\n",
       "\t\t<li>'8'</li>\n",
       "\t\t<li>'9'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 4\n",
       "\\item 5\n",
       "\\item 6\n",
       "\\item 7\n",
       "\\item 8\n",
       "\\item 9\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item '0'\n",
       "\\item '1'\n",
       "\\item '2'\n",
       "\\item '3'\n",
       "\\item '4'\n",
       "\\item '5'\n",
       "\\item '6'\n",
       "\\item '7'\n",
       "\\item '8'\n",
       "\\item '9'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 1\n",
       "3. 2\n",
       "4. 3\n",
       "5. 4\n",
       "6. 5\n",
       "7. 6\n",
       "8. 7\n",
       "9. 8\n",
       "10. 9\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. '0'\n",
       "2. '1'\n",
       "3. '2'\n",
       "4. '3'\n",
       "5. '4'\n",
       "6. '5'\n",
       "7. '6'\n",
       "8. '7'\n",
       "9. '8'\n",
       "10. '9'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0 1 2 3 4 5 6 7 8 9\n",
       "Levels: 0 1 2 3 4 5 6 7 8 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique(train_data$batch)\n",
    "label_levels = train_data$open_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features = train_data[c('signal', 'batch', 'time')]\n",
    "train_data_labels = train_data['open_channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features_matrix = data.matrix(train_data_features)\n",
    "train_data_labels_matrix =  data.matrix(train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numberOfTrainingSamples <- round(length(train_data) * split)\n",
    "\n",
    "# training data\n",
    "train_data <- train_data_features_matrix[1:numberOfTrainingSamples,]\n",
    "train_labels <- train_data_labels_matrix[1:numberOfTrainingSamples]\n",
    "\n",
    "# testing data\n",
    "test_data <- train_data_features_matrix[-(1:numberOfTrainingSamples),]\n",
    "test_labels <- train_data_labels_matrix[-(1:numberOfTrainingSamples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.train <- xgb.DMatrix(data = train_data, label = train_labels)\n",
    "xgb.test <- xgb.DMatrix(data = test_data, label = test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(\n",
    "  booster=\"gbtree\",\n",
    "  eta=0.001,\n",
    "  max_depth=5,\n",
    "  gamma=3,\n",
    "  subsample=0.75,\n",
    "  colsample_bytree=1,\n",
    "  objective=\"multi:softprob\",\n",
    "  eval_metric=\"mlogloss\",\n",
    "  num_class=length(unique(label_levels))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit=xgb.train(\n",
    "    params=params,\n",
    "    data=xgb.train,\n",
    "    nrounds=10000,\n",
    "    nthreads=1,\n",
    "    early_stopping_rounds=10,\n",
    "    watchlist=list(val1=xgb.train,val2=xgb.test),\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "##### xgb.Booster\n",
       "raw: 127.9 Kb \n",
       "call:\n",
       "  xgb.train(params = params, data = xgb.train, nrounds = 10000, \n",
       "    watchlist = list(val1 = xgb.train, val2 = xgb.test), verbose = 0, \n",
       "    early_stopping_rounds = 10, nthreads = 1)\n",
       "params (as set within xgb.train):\n",
       "  booster = \"gbtree\", eta = \"0.001\", max_depth = \"5\", gamma = \"3\", subsample = \"0.75\", colsample_bytree = \"1\", objective = \"multi:softprob\", eval_metric = \"mlogloss\", num_class = \"11\", nthreads = \"1\", silent = \"1\"\n",
       "xgb.attributes:\n",
       "  best_iteration, best_msg, best_ntreelimit, best_score, niter\n",
       "callbacks:\n",
       "  cb.evaluation.log()\n",
       "  cb.early.stop(stopping_rounds = early_stopping_rounds, maximize = maximize, \n",
       "    verbose = verbose)\n",
       "# of features: 3 \n",
       "niter: 63\n",
       "best_iteration : 53 \n",
       "best_ntreelimit : 53 \n",
       "best_score : 2.37085 \n",
       "nfeatures : 3 \n",
       "evaluation_log:\n",
       "    iter val1_mlogloss val2_mlogloss\n",
       "       1      2.397052      2.383855\n",
       "       2      2.396229      2.383826\n",
       "---                                 \n",
       "      62      2.311935      2.380293\n",
       "      63      2.310223      2.380261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict outcomes with the test data\n",
    "xgb.pred = predict(xgb.fit,test_data,reshape=T)\n",
    "xgb.pred = as.data.frame(xgb.pred)\n",
    "colnames(xgb.pred) = unique(label_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>0</th><th scope=col>1</th><th scope=col>3</th><th scope=col>2</th><th scope=col>10</th><th scope=col>9</th><th scope=col>8</th><th scope=col>7</th><th scope=col>6</th><th scope=col>5</th><th scope=col>4</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.09787406</td><td>0.09022623</td><td>0.09021507</td><td>0.09020449</td><td>0.09021686</td><td>0.09015597</td><td>0.09026237</td><td>0.09020745</td><td>0.09021912</td><td>0.09020568</td><td>0.09021274</td></tr>\n",
       "\t<tr><td>0.09787406</td><td>0.09022623</td><td>0.09021507</td><td>0.09020449</td><td>0.09021686</td><td>0.09015597</td><td>0.09026237</td><td>0.09020745</td><td>0.09021912</td><td>0.09020568</td><td>0.09021274</td></tr>\n",
       "\t<tr><td>0.09787406</td><td>0.09022623</td><td>0.09021507</td><td>0.09020449</td><td>0.09021686</td><td>0.09015597</td><td>0.09026237</td><td>0.09020745</td><td>0.09021912</td><td>0.09020568</td><td>0.09021274</td></tr>\n",
       "\t<tr><td>0.09787406</td><td>0.09022623</td><td>0.09021507</td><td>0.09020449</td><td>0.09021686</td><td>0.09015597</td><td>0.09026237</td><td>0.09020745</td><td>0.09021912</td><td>0.09020568</td><td>0.09021274</td></tr>\n",
       "\t<tr><td>0.09787406</td><td>0.09022623</td><td>0.09021507</td><td>0.09020449</td><td>0.09021686</td><td>0.09015597</td><td>0.09026237</td><td>0.09020745</td><td>0.09021912</td><td>0.09020568</td><td>0.09021274</td></tr>\n",
       "\t<tr><td>0.09787406</td><td>0.09022623</td><td>0.09021507</td><td>0.09020449</td><td>0.09021686</td><td>0.09015597</td><td>0.09026237</td><td>0.09020745</td><td>0.09021912</td><td>0.09020568</td><td>0.09021274</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       " 0 & 1 & 3 & 2 & 10 & 9 & 8 & 7 & 6 & 5 & 4\\\\\n",
       "\\hline\n",
       "\t 0.09787406 & 0.09022623 & 0.09021507 & 0.09020449 & 0.09021686 & 0.09015597 & 0.09026237 & 0.09020745 & 0.09021912 & 0.09020568 & 0.09021274\\\\\n",
       "\t 0.09787406 & 0.09022623 & 0.09021507 & 0.09020449 & 0.09021686 & 0.09015597 & 0.09026237 & 0.09020745 & 0.09021912 & 0.09020568 & 0.09021274\\\\\n",
       "\t 0.09787406 & 0.09022623 & 0.09021507 & 0.09020449 & 0.09021686 & 0.09015597 & 0.09026237 & 0.09020745 & 0.09021912 & 0.09020568 & 0.09021274\\\\\n",
       "\t 0.09787406 & 0.09022623 & 0.09021507 & 0.09020449 & 0.09021686 & 0.09015597 & 0.09026237 & 0.09020745 & 0.09021912 & 0.09020568 & 0.09021274\\\\\n",
       "\t 0.09787406 & 0.09022623 & 0.09021507 & 0.09020449 & 0.09021686 & 0.09015597 & 0.09026237 & 0.09020745 & 0.09021912 & 0.09020568 & 0.09021274\\\\\n",
       "\t 0.09787406 & 0.09022623 & 0.09021507 & 0.09020449 & 0.09021686 & 0.09015597 & 0.09026237 & 0.09020745 & 0.09021912 & 0.09020568 & 0.09021274\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0 | 1 | 3 | 2 | 10 | 9 | 8 | 7 | 6 | 5 | 4 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0.09787406 | 0.09022623 | 0.09021507 | 0.09020449 | 0.09021686 | 0.09015597 | 0.09026237 | 0.09020745 | 0.09021912 | 0.09020568 | 0.09021274 |\n",
       "| 0.09787406 | 0.09022623 | 0.09021507 | 0.09020449 | 0.09021686 | 0.09015597 | 0.09026237 | 0.09020745 | 0.09021912 | 0.09020568 | 0.09021274 |\n",
       "| 0.09787406 | 0.09022623 | 0.09021507 | 0.09020449 | 0.09021686 | 0.09015597 | 0.09026237 | 0.09020745 | 0.09021912 | 0.09020568 | 0.09021274 |\n",
       "| 0.09787406 | 0.09022623 | 0.09021507 | 0.09020449 | 0.09021686 | 0.09015597 | 0.09026237 | 0.09020745 | 0.09021912 | 0.09020568 | 0.09021274 |\n",
       "| 0.09787406 | 0.09022623 | 0.09021507 | 0.09020449 | 0.09021686 | 0.09015597 | 0.09026237 | 0.09020745 | 0.09021912 | 0.09020568 | 0.09021274 |\n",
       "| 0.09787406 | 0.09022623 | 0.09021507 | 0.09020449 | 0.09021686 | 0.09015597 | 0.09026237 | 0.09020745 | 0.09021912 | 0.09020568 | 0.09021274 |\n",
       "\n"
      ],
      "text/plain": [
       "  0          1          3          2          10         9          8         \n",
       "1 0.09787406 0.09022623 0.09021507 0.09020449 0.09021686 0.09015597 0.09026237\n",
       "2 0.09787406 0.09022623 0.09021507 0.09020449 0.09021686 0.09015597 0.09026237\n",
       "3 0.09787406 0.09022623 0.09021507 0.09020449 0.09021686 0.09015597 0.09026237\n",
       "4 0.09787406 0.09022623 0.09021507 0.09020449 0.09021686 0.09015597 0.09026237\n",
       "5 0.09787406 0.09022623 0.09021507 0.09020449 0.09021686 0.09015597 0.09026237\n",
       "6 0.09787406 0.09022623 0.09021507 0.09020449 0.09021686 0.09015597 0.09026237\n",
       "  7          6          5          4         \n",
       "1 0.09020745 0.09021912 0.09020568 0.09021274\n",
       "2 0.09020745 0.09021912 0.09020568 0.09021274\n",
       "3 0.09020745 0.09021912 0.09020568 0.09021274\n",
       "4 0.09020745 0.09021912 0.09020568 0.09021274\n",
       "5 0.09020745 0.09021912 0.09020568 0.09021274\n",
       "6 0.09020745 0.09021912 0.09020568 0.09021274"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(xgb.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the predicted label with the highest probability\n",
    "xgb.pred$prediction = apply(xgb.pred,1,function(x) colnames(xgb.pred)[which.max(x)])\n",
    "xgb.pred$label = unique(label_levels)[test_labels+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Final Accuracy = 24.80%\"\n"
     ]
    }
   ],
   "source": [
    "result = sum(xgb.pred$prediction==xgb.pred$label)/nrow(xgb.pred)\n",
    "print(paste(\"Final Accuracy =\",sprintf(\"%1.2f%%\", 100*result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
